{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ph√¢n t√≠ch One-way ANOVA: m·ª©c ƒë·ªô h√†i l√≤ng TMƒêT gi·ªØa c√°c th·∫ø h·ªá\n",
    "\n",
    "Notebook n√†y minh h·ªça quy tr√¨nh chu·∫©n c·ªßa m·ªôt b√†i nghi√™n c·ª©u ƒë·ªãnh l∆∞·ª£ng:\n",
    "\n",
    "1. ƒê·ªçc d·ªØ li·ªáu kh·∫£o s√°t\n",
    "2. T·∫°o bi·∫øn th·∫ø h·ªá (`generation`) v√† ƒëi·ªÉm h√†i l√≤ng t·ªïng h·ª£p (`satisfaction`)\n",
    "3. Th·ªëng k√™ m√¥ t·∫£ v√† v·∫Ω bi·ªÉu ƒë·ªì\n",
    "4. Ki·ªÉm tra gi·∫£ ƒë·ªãnh tr∆∞·ªõc khi d√πng one-way ANOVA (chu·∫©n, ƒë·ªìng nh·∫•t ph∆∞∆°ng sai)\n",
    "5. Th·ª±c hi·ªán ANOVA\n",
    "6. Ki·ªÉm ƒë·ªãnh h·∫≠u nghi·ªám Tukey HSD\n",
    "7. G·ª£i √Ω c√°ch vi·∫øt k·∫øt lu·∫≠n cho b√†i nghi√™n c·ª©u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import shapiro, levene, f_oneway\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "sns.set(style=\"whitegrid\", font_scale=1.1)\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 1 ‚Äì ƒê·ªçc d·ªØ li·ªáu kh·∫£o s√°t\n",
    "\n",
    "- File d·ªØ li·ªáu m·∫´u: `survey_data.csv`\n",
    "- C√°c c·ªôt ch√≠nh:\n",
    "  - `year_of_birth`: nƒÉm sinh ng∆∞·ªùi tr·∫£ l·ªùi\n",
    "  - `Q1`‚Äì`Q10`: c√°c c√¢u h·ªèi thang Likert 1‚Äì5 v·ªÅ h√†i l√≤ng TMƒêT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
    "# ƒê·∫£m b·∫£o file survey_data.csv n·∫±m c√πng th∆∞ m·ª•c v·ªõi notebook n√†y\n",
    "\n",
    "df = pd.read_csv(\"survey_data.csv\")\n",
    "print(\"5 d√≤ng ƒë·∫ßu d·ªØ li·ªáu:\")\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B∆∞·ªõc 2 ‚Äì T·∫°o bi·∫øn th·∫ø h·ªá (`generation`) v√† ƒëi·ªÉm h√†i l√≤ng (`satisfaction`)\n",
    "\n",
    "- M√£ h√≥a nƒÉm sinh th√†nh 3 th·∫ø h·ªá: Gen X, Millennials, Gen Z.\n",
    "- T·∫°o bi·∫øn `satisfaction` = trung b√¨nh ƒëi·ªÉm Q1‚ÄìQ10 cho m·ªói ng∆∞·ªùi tr·∫£ l·ªùi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√†m m√£ h√≥a nƒÉm sinh th√†nh th·∫ø h·ªá\n",
    "\n",
    "def map_generation(year):\n",
    "    if 1965 <= year <= 1980:\n",
    "        return \"Gen X\"\n",
    "    elif 1981 <= year <= 1996:\n",
    "        return \"Millennials\"\n",
    "    elif 1997 <= year <= 2012:\n",
    "        return \"Gen Z\"\n",
    "    else:\n",
    "        return \"Kh√°c\"\n",
    "\n",
    "# N·∫øu ch∆∞a c√≥ c·ªôt generation th√¨ t·∫°o m·ªõi\n",
    "if \"generation\" not in df.columns:\n",
    "    df[\"generation\"] = df[\"year_of_birth\"].apply(map_generation)\n",
    "\n",
    "# Gi·ªØ l·∫°i 3 nh√≥m ch√≠nh\n",
    "df = df[df[\"generation\"].isin([\"Gen X\", \"Millennials\", \"Gen Z\"])].copy()\n",
    "\n",
    "# T·∫°o bi·∫øn satisfaction t·ª´ Q1..Q10\n",
    "item_cols = [f\"Q{i}\" for i in range(1, 11)]\n",
    "\n",
    "df[\"satisfaction\"] = df[item_cols].mean(axis=1)\n",
    "\n",
    "print(\"5 d√≤ng ƒë·∫ßu sau khi t·∫°o generation v√† satisfaction:\")\n",
    "display(df[[\"year_of_birth\", \"generation\", \"satisfaction\"]].head())\n",
    "\n",
    "print(\"Ph√¢n b·ªë s·ªë l∆∞·ª£ng theo th·∫ø h·ªá:\")\n",
    "display(df[\"generation\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## B∆∞·ªõc 3.1 ‚Äì ƒê√°nh gi√° ƒë·ªô tin c·∫≠y thang ƒëo (Cronbach's Alpha)\n\nTr∆∞·ªõc khi ph√¢n t√≠ch ANOVA, c·∫ßn ki·ªÉm tra ƒë·ªô tin c·∫≠y c·ªßa thang ƒëo (10 m·ª•c h·ªèi Q1-Q10)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# H√†m t√≠nh Cronbach's Alpha\ndef cronbach_alpha(df_items):\n    \"\"\"T√≠nh Cronbach's Alpha cho thang ƒëo\"\"\"\n    item_variances = df_items.var(axis=0, ddof=1)\n    total_variance = df_items.sum(axis=1).var(ddof=1)\n    n_items = df_items.shape[1]\n    return n_items / (n_items - 1) * (1 - item_variances.sum() / total_variance)\n\n# T√≠nh Cronbach's Alpha\nalpha_overall = cronbach_alpha(df[item_cols])\nprint(f\"Cronbach's Alpha (to√†n b·ªô m·∫´u) = {alpha_overall:.4f}\")\n\n# T√≠nh alpha cho t·ª´ng nh√≥m\nprint(\"\\nCronbach's Alpha theo t·ª´ng th·∫ø h·ªá:\")\nfor gen in [\"Gen X\", \"Millennials\", \"Gen Z\"]:\n    df_gen = df[df[\"generation\"] == gen]\n    alpha_gen = cronbach_alpha(df_gen[item_cols])\n    print(f\"  {gen:12s}: Œ± = {alpha_gen:.4f}\")\n\n# ƒê√°nh gi√°\nif alpha_overall >= 0.9:\n    print(f\"\\n‚úÖ ƒê·ªô tin c·∫≠y XU·∫§T S·∫ÆC (Œ± ‚â• 0.9)\")\nelif alpha_overall >= 0.8:\n    print(f\"\\n‚úÖ ƒê·ªô tin c·∫≠y T·ªêT (0.8 ‚â§ Œ± < 0.9)\")\nelif alpha_overall >= 0.7:\n    print(f\"\\n‚ö†Ô∏è  ƒê·ªô tin c·∫≠y CH·∫§P NH·∫¨N ƒê∆Ø·ª¢C (0.7 ‚â§ Œ± < 0.8)\")\nelse:\n    print(f\"\\n‚ùå ƒê·ªô tin c·∫≠y TH·∫§P (Œ± < 0.7) - Thang ƒëo c·∫ßn xem x√©t l·∫°i!\")"
  },
  {
   "cell_type": "markdown",
   "source": "## B∆∞·ªõc 3.2 ‚Äì Th·ªëng k√™ m√¥ t·∫£ v√† bi·ªÉu ƒë·ªì",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## B∆∞·ªõc 4 ‚Äì Th·ª±c hi·ªán One-way ANOVA\n\n- Ki·ªÉm ƒë·ªãnh xem trung b√¨nh `satisfaction` c√≥ kh√°c nhau gi·ªØa 3 th·∫ø h·ªá.\n- H0: Œº(Gen Z) = Œº(Millennials) = Œº(Gen X).\n- H1: C√≥ √≠t nh·∫•t m·ªôt c·∫∑p trung b√¨nh kh√°c nhau."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ANOVA b·∫±ng scipy v√† b·∫£ng ANOVA chi ti·∫øt b·∫±ng statsmodels\n\nscores_z = df.loc[df[\"generation\"] == \"Gen Z\", \"satisfaction\"]\nscores_m = df.loc[df[\"generation\"] == \"Millennials\", \"satisfaction\"]\nscores_x = df.loc[df[\"generation\"] == \"Gen X\", \"satisfaction\"]\n\nf_stat, p_anova = f_oneway(scores_z, scores_m, scores_x)\nprint(f\"ANOVA (scipy) -> F = {f_stat:.3f}, p-value = {p_anova:.6f}\")\n\nmodel = ols('satisfaction ~ C(generation)', data=df).fit()\nanova_table = sm.stats.anova_lm(model, typ=2)\nprint(\"\\nB·∫£ng ANOVA (statsmodels):\")\ndisplay(anova_table)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## B∆∞·ªõc 5 ‚Äì Ki·ªÉm tra gi·∫£ ƒë·ªãnh ANOVA\n\nSau khi fit m√¥ h√¨nh ANOVA, c·∫ßn ki·ªÉm tra c√°c gi·∫£ ƒë·ªãnh:\n\n### 5.1. Gi·∫£ ƒë·ªãnh ph√¢n ph·ªëi chu·∫©n c·ªßa residuals\n\n- Gi·∫£ ƒë·ªãnh: Residuals (ph·∫ßn d∆∞) c√≥ ph√¢n ph·ªëi chu·∫©n N(0, œÉ¬≤)\n- Residual = y_i - »≥_nh√≥m_i (sai l·ªách gi·ªØa gi√° tr·ªã quan s√°t v√† trung b√¨nh nh√≥m)\n- Ki·ªÉm ƒë·ªãnh: Shapiro-Wilk v√† QQ plot\n- H0: Residuals c√≥ ph√¢n ph·ªëi chu·∫©n\n- N·∫øu p > 0.05 ‚Üí Kh√¥ng b√°c b·ªè H0 (ch·∫•p nh·∫≠n gi·∫£ ƒë·ªãnh)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# L·∫•y residuals t·ª´ m√¥ h√¨nh ANOVA\nresiduals = model.resid\n\n# Ki·ªÉm ƒë·ªãnh Shapiro-Wilk cho residuals\nstat_shapiro, p_shapiro = shapiro(residuals)\nprint(f\"Shapiro-Wilk test (residuals):\")\nprint(f\"  W = {stat_shapiro:.4f}\")\nprint(f\"  p-value = {p_shapiro:.4e}\")\n\nif p_shapiro > 0.05:\n    print(\"  => ‚úÖ KH√îNG b√°c b·ªè H0: Residuals c√≥ ph√¢n ph·ªëi chu·∫©n\")\nelse:\n    print(f\"  => ‚ö†Ô∏è  B√°c b·ªè H0: Residuals vi ph·∫°m gi·∫£ ƒë·ªãnh chu·∫©n (p={p_shapiro:.4e})\")\n    print(f\"  Tuy nhi√™n, v·ªõi n={len(df)} (l·ªõn) v√† c√¢n b·∫±ng, ANOVA v·∫´n robust.\")\n    \n# QQ plot ƒë·ªÉ ki·ªÉm tra tr·ª±c quan\nimport scipy.stats as stats\n\nfig, ax = plt.subplots(figsize=(8, 6))\nstats.probplot(residuals, dist=\"norm\", plot=ax)\nax.set_title(\"Q-Q Plot: Ki·ªÉm tra ph√¢n ph·ªëi chu·∫©n c·ªßa Residuals\", fontsize=14, fontweight='bold')\nax.set_xlabel(\"Theoretical Quantiles (Ph√¢n v·ªã l√Ω thuy·∫øt)\", fontsize=12)\nax.set_ylabel(\"Sample Quantiles (Ph√¢n v·ªã m·∫´u)\", fontsize=12)\nax.grid(True, alpha=0.3)\nplt.tight_layout()\nplt.savefig(\"fig4_qqplot_residuals.png\", dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(\"\\nüí° C√°ch ƒë·ªçc QQ plot:\")\nprint(\"   - ƒêi·ªÉm n·∫±m S√ÅT ƒë∆∞·ªùng th·∫≥ng ‚Üí Residuals ph√¢n ph·ªëi chu·∫©n\")\nprint(\"   - ƒêi·ªÉm L·ªÜCH ·ªü 2 ƒë·∫ßu ‚Üí Vi ph·∫°m nh·∫π, ch·∫•p nh·∫≠n ƒë∆∞·ª£c v·ªõi n l·ªõn\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5.2. Gi·∫£ ƒë·ªãnh ƒë·ªìng nh·∫•t ph∆∞∆°ng sai (Homogeneity of Variance)\n\n- Gi·∫£ ƒë·ªãnh: Ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu trong c√°c nh√≥m b·∫±ng nhau\n- Var(Gen X) = Var(Millennials) = Var(Gen Z)\n- Ki·ªÉm ƒë·ªãnh: Levene test\n- H0: Ph∆∞∆°ng sai c√°c nh√≥m b·∫±ng nhau\n- N·∫øu p > 0.05 ‚Üí Kh√¥ng b√°c b·ªè H0 (ch·∫•p nh·∫≠n gi·∫£ ƒë·ªãnh)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Ki·ªÉm tra ph∆∞∆°ng sai t·ª´ng nh√≥m\nprint(\"Ph∆∞∆°ng sai (variance) t·ª´ng nh√≥m:\")\nfor gen in [\"Gen X\", \"Millennials\", \"Gen Z\"]:\n    scores = df[df[\"generation\"] == gen][\"satisfaction\"]\n    var = scores.var(ddof=1)\n    std = scores.std(ddof=1)\n    print(f\"  {gen:12s}: Var = {var:.4f}, SD = {std:.4f}\")\n\n# T·ª∑ l·ªá ph∆∞∆°ng sai max/min\nvariances = [df[df[\"generation\"] == gen][\"satisfaction\"].var(ddof=1) \n             for gen in [\"Gen X\", \"Millennials\", \"Gen Z\"]]\nratio = max(variances) / min(variances)\nprint(f\"\\nT·ª∑ l·ªá ph∆∞∆°ng sai max/min = {ratio:.2f}\")\nprint(f\"  (N·∫øu < 3 ‚Üí Ch·∫•p nh·∫≠n ƒë∆∞·ª£c theo quy t·∫Øc th·ª±c nghi·ªám)\")\n\n# Levene test\nstat_levene, p_levene = levene(scores_x, scores_m, scores_z)\nprint(f\"\\nLevene test:\")\nprint(f\"  F = {stat_levene:.2f}\")\nprint(f\"  p-value = {p_levene:.4e}\")\n\nif p_levene > 0.05:\n    print(\"  => ‚úÖ KH√îNG b√°c b·ªè H0: Ph∆∞∆°ng sai c√°c nh√≥m b·∫±ng nhau\")\nelse:\n    print(f\"  => ‚ö†Ô∏è  B√°c b·ªè H0: Ph∆∞∆°ng sai c√°c nh√≥m KH√ÅC NHAU (p={p_levene:.4e})\")\n    print(f\"  Tuy nhi√™n, t·ª∑ l·ªá={ratio:.2f}<3 v√† n c√¢n b·∫±ng ‚Üí ANOVA v·∫´n robust\")\n    print(f\"  N√™n ki·ªÉm ch·ª©ng b·∫±ng Welch ANOVA ho·∫∑c Kruskal-Wallis\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## B∆∞·ªõc 6 ‚Äì Ki·ªÉm ƒë·ªãnh h·∫≠u nghi·ªám Tukey HSD\n\n- Th·ª±c hi·ªán khi ANOVA c√≥ √Ω nghƒ©a (p-value < 0.05).\n- M·ª•c ti√™u: xem c·∫∑p th·∫ø h·ªá n√†o kh√°c nhau v·ªÅ m·ª©c h√†i l√≤ng."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if p_anova < 0.05:\n",
    "    print(\"V√¨ p-value ANOVA < 0.05 n√™n th·ª±c hi·ªán ki·ªÉm ƒë·ªãnh h·∫≠u nghi·ªám Tukey HSD:\")\n",
    "    tukey = pairwise_tukeyhsd(endog=df['satisfaction'],\n",
    "                              groups=df['generation'],\n",
    "                              alpha=0.05)\n",
    "    print(tukey)\n",
    "else:\n",
    "    print(\"p-value ANOVA >= 0.05: kh√¥ng ƒë·ªß b·∫±ng ch·ª©ng kh√°c bi·ªát gi·ªØa c√°c th·∫ø h·ªá, th∆∞·ªùng kh√¥ng c·∫ßn Tukey.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## B∆∞·ªõc 7 ‚Äì G·ª£i √Ω c√°ch vi·∫øt k·∫øt lu·∫≠n\n\nCell d∆∞·ªõi ƒë√¢y in ra g·ª£i √Ω k·∫øt lu·∫≠n ƒë·ªÉ tham kh·∫£o khi vi·∫øt b√°o c√°o (n√™u F, p v√† di·ªÖn gi·∫£i H0)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "# L·∫•y b·∫≠c t·ª± do t·ª´ b·∫£ng ANOVA\n",
    "df_between = int(anova_table.loc['C(generation)', 'df'])\n",
    "df_within = int(anova_table.loc['Residual', 'df'])\n",
    "\n",
    "print(\"--- G·ª¢I √ù K·∫æT LU·∫¨N ---\")\n",
    "print(f\"K·∫øt qu·∫£ ANOVA m·ªôt nh√¢n t·ªë cho th·∫•y F({df_between}, {df_within}) = {f_stat:.2f}, p = {p_anova:.4f}.\")\n",
    "\n",
    "if p_anova < alpha:\n",
    "    print(\"V√¨ p < 0.05 n√™n b√°c b·ªè gi·∫£ thuy·∫øt H0: c√≥ s·ª± kh√°c bi·ªát c√≥ √Ω nghƒ©a th·ªëng k√™ v·ªÅ m·ª©c ƒë·ªô h√†i l√≤ng TMƒêT gi·ªØa √≠t nh·∫•t hai th·∫ø h·ªá.\")\n",
    "    print(\"H·ªçc sinh c√≥ th·ªÉ d·ª±a v√†o b·∫£ng Tukey ƒë·ªÉ m√¥ t·∫£ c·ª• th·ªÉ c·∫∑p th·∫ø h·ªá n√†o kh√°c nhau (v√≠ d·ª•: Gen Z > Gen X).\")\n",
    "else:\n",
    "    print(\"V√¨ p ‚â• 0.05 n√™n kh√¥ng b√°c b·ªè gi·∫£ thuy·∫øt H0: kh√¥ng t√¨m th·∫•y b·∫±ng ch·ª©ng ƒë·ªß m·∫°nh v·ªÅ s·ª± kh√°c bi·ªát m·ª©c ƒë·ªô h√†i l√≤ng TMƒêT gi·ªØa c√°c th·∫ø h·ªá.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## B∆∞·ªõc 8 ‚Äì Ki·ªÉm ƒë·ªãnh Kruskal-Wallis (ki·ªÉm ch·ª©ng, phi tham s·ªë)\n\nƒê·ªÉ ki·ªÉm tra ƒë·ªô b·ªÅn v·ªØng c·ªßa k·∫øt lu·∫≠n khi gi·∫£ ƒë·ªãnh b·ªã vi ph·∫°m nh·∫π, ta d√πng th√™m ki·ªÉm ƒë·ªãnh phi tham s·ªë **Kruskal-Wallis** (so s√°nh ba nh√≥m d·ª±a tr√™n th·ª© h·∫°ng, kh√¥ng y√™u c·∫ßu ph√¢n ph·ªëi chu·∫©n)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Kruskal‚ÄìWallis cho ba nh√≥m th·∫ø h·ªá\n",
    "H_stat, p_kw = kruskal(scores_x, scores_m, scores_z)\n",
    "print(f\"Kruskal‚ÄìWallis: H(2) = {H_stat:.3f}, p = {p_kw:.3g}\")\n",
    "\n",
    "if p_kw < 0.05:\n",
    "    print(\"=> B√°c b·ªè H0: c√≥ s·ª± kh√°c bi·ªát c√≥ √Ω nghƒ©a th·ªëng k√™ v·ªÅ m·ª©c ƒë·ªô h√†i l√≤ng gi·ªØa √≠t nh·∫•t hai th·∫ø h·ªá (theo ki·ªÉm ƒë·ªãnh phi tham s·ªë).\")\n",
    "else:\n",
    "    print(\"=> Kh√¥ng b√°c b·ªè H0: kh√¥ng t√¨m th·∫•y kh√°c bi·ªát c√≥ √Ω nghƒ©a (theo ki·ªÉm ƒë·ªãnh phi tham s·ªë).\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}